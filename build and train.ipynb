{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sensitive-democracy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:39:01.972595Z",
     "start_time": "2021-02-06T15:38:58.360336Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "innovative-affect",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:39:01.983335Z",
     "start_time": "2021-02-06T15:39:01.974504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1107547 characters\n"
     ]
    }
   ],
   "source": [
    "text = open('ptter4.txt', 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "continental-bradley",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:39:01.994689Z",
     "start_time": "2021-02-06T15:39:01.986498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HARRY POTTER AND THE GOBLET OF FIRE\n",
      "\n",
      "CHAPTER ONE - THE RIDDLE HOUSE\n",
      "\n",
      "\tThe villagers of Little Hangleron still called it \"the Riddle House,\" even though it had been many years since the Riddle family had lived there.  It stood on a hill overlooking th\n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "shaped-console",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:39:02.047094Z",
     "start_time": "2021-02-06T15:39:01.997565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abstract-remark",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:39:02.124893Z",
     "start_time": "2021-02-06T15:39:02.049338Z"
    }
   },
   "outputs": [],
   "source": [
    "ids_from_chars = preprocessing.StringLookup(\n",
    "    vocabulary=list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "furnished-forest",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:39:02.149664Z",
     "start_time": "2021-02-06T15:39:02.131389Z"
    }
   },
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "announced-botswana",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:39:02.158968Z",
     "start_time": "2021-02-06T15:39:02.152728Z"
    }
   },
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "addressed-insulation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:39:02.893276Z",
     "start_time": "2021-02-06T15:39:02.166750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1107547,), dtype=int64, numpy=array([33, 26, 43, ..., 12,  3,  3])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bearing-biotechnology",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:39:02.899977Z",
     "start_time": "2021-02-06T15:39:02.895346Z"
    }
   },
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial-proceeding",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:39:02.946773Z",
     "start_time": "2021-02-06T15:39:02.901632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H\n",
      "A\n",
      "R\n",
      "R\n",
      "Y\n",
      " \n",
      "P\n",
      "O\n",
      "T\n",
      "T\n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "third-sellers",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:39:02.951864Z",
     "start_time": "2021-02-06T15:39:02.948838Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "voluntary-cookie",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:39:02.979151Z",
     "start_time": "2021-02-06T15:39:02.960086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'H' b'A' b'R' b'R' b'Y' b' ' b'P' b'O' b'T' b'T' b'E' b'R' b' ' b'A'\n",
      " b'N' b'D' b' ' b'T' b'H' b'E' b' ' b'G' b'O' b'B' b'L' b'E' b'T' b' '\n",
      " b'O' b'F' b' ' b'F' b'I' b'R' b'E' b'\\n' b'\\n' b'C' b'H' b'A' b'P' b'T'\n",
      " b'E' b'R' b' ' b'O' b'N' b'E' b' ' b'-' b' ' b'T' b'H' b'E' b' ' b'R'\n",
      " b'I' b'D' b'D' b'L' b'E' b' ' b'H' b'O' b'U' b'S' b'E' b'\\n' b'\\n' b'\\t'\n",
      " b'T' b'h' b'e' b' ' b'v' b'i' b'l' b'l' b'a' b'g' b'e' b'r' b's' b' '\n",
      " b'o' b'f' b' ' b'L' b'i' b't' b't' b'l' b'e' b' ' b'H' b'a' b'n' b'g'\n",
      " b'l' b'e' b'r'], shape=(101,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'o' b'n' b' ' b's' b't' b'i' b'l' b'l' b' ' b'c' b'a' b'l' b'l' b'e'\n",
      " b'd' b' ' b'i' b't' b' ' b'\"' b't' b'h' b'e' b' ' b'R' b'i' b'd' b'd'\n",
      " b'l' b'e' b' ' b'H' b'o' b'u' b's' b'e' b',' b'\"' b' ' b'e' b'v' b'e'\n",
      " b'n' b' ' b't' b'h' b'o' b'u' b'g' b'h' b' ' b'i' b't' b' ' b'h' b'a'\n",
      " b'd' b' ' b'b' b'e' b'e' b'n' b' ' b'm' b'a' b'n' b'y' b' ' b'y' b'e'\n",
      " b'a' b'r' b's' b' ' b's' b'i' b'n' b'c' b'e' b' ' b't' b'h' b'e' b' '\n",
      " b'R' b'i' b'd' b'd' b'l' b'e' b' ' b'f' b'a' b'm' b'i' b'l' b'y' b' '\n",
      " b'h' b'a' b'd'], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(2):\n",
    "    print(chars_from_ids(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "conservative-satisfaction",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:39:03.016340Z",
     "start_time": "2021-02-06T15:39:02.982784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'HARRY POTTER AND THE GOBLET OF FIRE\\n\\nCHAPTER ONE - THE RIDDLE HOUSE\\n\\n\\tThe villagers of Little Hangler'\n",
      "b'on still called it \"the Riddle House,\" even though it had been many years since the Riddle family had'\n",
      "b' lived there.  It stood on a hill overlooking the village, some of its windows boarded, tiles missing'\n",
      "b' from its roof, and ivy spreading unchecked over its face.  Once a fine-looking manor, and easily the'\n",
      "b' largest and grandest building for miles around, the Riddle House was now damp, derelict, and unoccup'\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "    print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "blessed-performer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:39:03.024527Z",
     "start_time": "2021-02-06T15:39:03.018251Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "scheduled-peeing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:40:42.943393Z",
     "start_time": "2021-02-06T15:40:42.842507Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "three-ambassador",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:40:50.725945Z",
     "start_time": "2021-02-06T15:40:50.697511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b'HARRY POTTER AND THE GOBLET OF FIRE\\n\\nCHAPTER ONE - THE RIDDLE HOUSE\\n\\n\\tThe villagers of Little Hangle'\n",
      "Target: b'ARRY POTTER AND THE GOBLET OF FIRE\\n\\nCHAPTER ONE - THE RIDDLE HOUSE\\n\\n\\tThe villagers of Little Hangler'\n",
      "Input : b'on still called it \"the Riddle House,\" even though it had been many years since the Riddle family ha'\n",
      "Target: b'n still called it \"the Riddle House,\" even though it had been many years since the Riddle family had'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(2):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "embedded-implementation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:40:50.737230Z",
     "start_time": "2021-02-06T15:40:50.728672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "settled-hepatitis",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:40:50.750007Z",
     "start_time": "2021-02-06T15:40:50.739244Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "capital-engineer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:40:50.762000Z",
     "start_time": "2021-02-06T15:40:50.751894Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True, \n",
    "                                   return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x=inputs\n",
    "        x=self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "        \n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "killing-accent",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:40:50.814105Z",
     "start_time": "2021-02-06T15:40:50.763569Z"
    }
   },
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size = len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim = embedding_dim,\n",
    "    rnn_units = rnn_units\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "unsigned-leader",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:40:54.113476Z",
     "start_time": "2021-02-06T15:40:50.818929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 82) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "naughty-purchase",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:40:54.124905Z",
     "start_time": "2021-02-06T15:40:54.116279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  20992     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    multiple                  3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  84050     \n",
      "=================================================================\n",
      "Total params: 4,043,346\n",
      "Trainable params: 4,043,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "planned-album",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:40:54.145696Z",
     "start_time": "2021-02-06T15:40:54.130419Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "governmental-norwegian",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:40:54.215810Z",
     "start_time": "2021-02-06T15:40:54.150591Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "specified-intensity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:40:54.239691Z",
     "start_time": "2021-02-06T15:40:54.218660Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpointsV2'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "married-taxation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-06T15:40:54.250040Z",
     "start_time": "2021-02-06T15:40:54.242676Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "super-excerpt",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T00:15:36.533927Z",
     "start_time": "2021-02-06T15:40:54.253121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "171/171 [==============================] - 567s 3s/step - loss: 3.2514\n",
      "Epoch 2/60\n",
      "171/171 [==============================] - 554s 3s/step - loss: 2.0565\n",
      "Epoch 3/60\n",
      "171/171 [==============================] - 512s 3s/step - loss: 1.6693\n",
      "Epoch 4/60\n",
      "171/171 [==============================] - 492s 3s/step - loss: 1.4467\n",
      "Epoch 5/60\n",
      "171/171 [==============================] - 609s 4s/step - loss: 1.3137\n",
      "Epoch 6/60\n",
      "171/171 [==============================] - 846s 5s/step - loss: 1.2275\n",
      "Epoch 7/60\n",
      "171/171 [==============================] - 824s 5s/step - loss: 1.1673\n",
      "Epoch 8/60\n",
      "171/171 [==============================] - 519s 3s/step - loss: 1.1099\n",
      "Epoch 9/60\n",
      "171/171 [==============================] - 510s 3s/step - loss: 1.0661\n",
      "Epoch 10/60\n",
      "171/171 [==============================] - 514s 3s/step - loss: 1.0196\n",
      "Epoch 11/60\n",
      "171/171 [==============================] - 509s 3s/step - loss: 0.9751\n",
      "Epoch 12/60\n",
      "171/171 [==============================] - 512s 3s/step - loss: 0.9314\n",
      "Epoch 13/60\n",
      "171/171 [==============================] - 511s 3s/step - loss: 0.8882\n",
      "Epoch 14/60\n",
      "171/171 [==============================] - 522s 3s/step - loss: 0.8405\n",
      "Epoch 15/60\n",
      "171/171 [==============================] - 575s 3s/step - loss: 0.7948\n",
      "Epoch 16/60\n",
      "171/171 [==============================] - 578s 3s/step - loss: 0.7488\n",
      "Epoch 17/60\n",
      "171/171 [==============================] - 535s 3s/step - loss: 0.7033\n",
      "Epoch 18/60\n",
      "171/171 [==============================] - 509s 3s/step - loss: 0.6600\n",
      "Epoch 19/60\n",
      "171/171 [==============================] - 510s 3s/step - loss: 0.6190\n",
      "Epoch 20/60\n",
      "171/171 [==============================] - 509s 3s/step - loss: 0.5815\n",
      "Epoch 21/60\n",
      "171/171 [==============================] - 510s 3s/step - loss: 0.5503\n",
      "Epoch 22/60\n",
      "171/171 [==============================] - 510s 3s/step - loss: 0.5215\n",
      "Epoch 23/60\n",
      "171/171 [==============================] - 510s 3s/step - loss: 0.4958\n",
      "Epoch 24/60\n",
      "171/171 [==============================] - 512s 3s/step - loss: 0.4759\n",
      "Epoch 25/60\n",
      "171/171 [==============================] - 509s 3s/step - loss: 0.4599\n",
      "Epoch 26/60\n",
      "171/171 [==============================] - 524s 3s/step - loss: 0.4449\n",
      "Epoch 27/60\n",
      "171/171 [==============================] - 510s 3s/step - loss: 0.4317\n",
      "Epoch 28/60\n",
      "171/171 [==============================] - 509s 3s/step - loss: 0.4246\n",
      "Epoch 29/60\n",
      "171/171 [==============================] - 508s 3s/step - loss: 0.4151\n",
      "Epoch 30/60\n",
      "171/171 [==============================] - 480s 3s/step - loss: 0.4103\n",
      "Epoch 31/60\n",
      "171/171 [==============================] - 486s 3s/step - loss: 0.4022\n",
      "Epoch 32/60\n",
      "171/171 [==============================] - 486s 3s/step - loss: 0.3968\n",
      "Epoch 33/60\n",
      "171/171 [==============================] - 485s 3s/step - loss: 0.3964\n",
      "Epoch 34/60\n",
      "171/171 [==============================] - 485s 3s/step - loss: 0.3947\n",
      "Epoch 35/60\n",
      "171/171 [==============================] - 487s 3s/step - loss: 0.3964\n",
      "Epoch 36/60\n",
      "171/171 [==============================] - 484s 3s/step - loss: 0.3933\n",
      "Epoch 37/60\n",
      "171/171 [==============================] - 485s 3s/step - loss: 0.3913\n",
      "Epoch 38/60\n",
      "171/171 [==============================] - 486s 3s/step - loss: 0.3859\n",
      "Epoch 39/60\n",
      "171/171 [==============================] - 486s 3s/step - loss: 0.3864\n",
      "Epoch 40/60\n",
      "171/171 [==============================] - 485s 3s/step - loss: 0.3877\n",
      "Epoch 41/60\n",
      "171/171 [==============================] - 485s 3s/step - loss: 0.3892\n",
      "Epoch 42/60\n",
      "171/171 [==============================] - 485s 3s/step - loss: 0.3918\n",
      "Epoch 43/60\n",
      "171/171 [==============================] - 483s 3s/step - loss: 0.3889\n",
      "Epoch 44/60\n",
      "171/171 [==============================] - 484s 3s/step - loss: 0.3939\n",
      "Epoch 45/60\n",
      "171/171 [==============================] - 485s 3s/step - loss: 0.3978\n",
      "Epoch 46/60\n",
      "171/171 [==============================] - 486s 3s/step - loss: 0.3987\n",
      "Epoch 47/60\n",
      "171/171 [==============================] - 483s 3s/step - loss: 0.4038\n",
      "Epoch 48/60\n",
      "171/171 [==============================] - 483s 3s/step - loss: 0.4123\n",
      "Epoch 49/60\n",
      "171/171 [==============================] - 485s 3s/step - loss: 0.4107\n",
      "Epoch 50/60\n",
      "171/171 [==============================] - 482s 3s/step - loss: 0.4150\n",
      "Epoch 51/60\n",
      "171/171 [==============================] - 483s 3s/step - loss: 0.4123\n",
      "Epoch 52/60\n",
      "171/171 [==============================] - 483s 3s/step - loss: 0.4147\n",
      "Epoch 53/60\n",
      "171/171 [==============================] - 484s 3s/step - loss: 0.4235\n",
      "Epoch 54/60\n",
      "171/171 [==============================] - 490s 3s/step - loss: 0.4282\n",
      "Epoch 55/60\n",
      "171/171 [==============================] - 489s 3s/step - loss: 0.4239\n",
      "Epoch 56/60\n",
      "171/171 [==============================] - 491s 3s/step - loss: 0.4417\n",
      "Epoch 57/60\n",
      "171/171 [==============================] - 489s 3s/step - loss: 0.4449\n",
      "Epoch 58/60\n",
      "171/171 [==============================] - 491s 3s/step - loss: 0.4562\n",
      "Epoch 59/60\n",
      "171/171 [==============================] - 491s 3s/step - loss: 0.4549\n",
      "Epoch 60/60\n",
      "171/171 [==============================] - 492s 3s/step - loss: 0.4632\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "increasing-driving",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T00:15:36.549437Z",
     "start_time": "2021-02-07T00:15:36.536689Z"
    }
   },
   "outputs": [],
   "source": [
    "class NextStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature=temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"\" or \"[UNK]\" from being generated.\n",
    "        skip_ids = self.ids_from_chars(['','[UNK]'])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices = skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())]) \n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_next_step(self, inputs, states=None):\n",
    "        # Convert strings to token IDs.\n",
    "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "        print('Input shape',input_ids.shape)\n",
    "        # Run the model.\n",
    "        # predicted_logits.shape is [batch, char, next_char_logits] \n",
    "        predicted_logits, states =  self.model(inputs=input_ids, states=states, \n",
    "                                          return_state=True)\n",
    "        # Only use the last prediction.\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits/self.temperature\n",
    "        # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        # Sample the output logits to generate token IDs.\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # Convert from token ids to characters\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "        \n",
    "        # Return the characters and model state.\n",
    "        return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "convinced-virus",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T00:15:36.596193Z",
     "start_time": "2021-02-07T00:15:36.552080Z"
    }
   },
   "outputs": [],
   "source": [
    "next_step_model = NextStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "retained-reasoning",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T00:15:37.890919Z",
     "start_time": "2021-02-07T00:15:36.600992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (5, None)\n",
      "Input shape (5, None)\n",
      "tf.Tensor(\n",
      "[b'Forestble friends.\"\\nDumbledore gave the paper with Padma asked him toward them. \"We\\'re still worried, and '\n",
      " b'the train began to move up.  For Harry took the right-panished, he threw giants, his arms were filiedly down '\n",
      " b'Platformarm,\" said the cold voice.  \"Where\\'s Hermione, who are going to lunching much less in his companion '\n",
      " b'Bankant-colored straws.  He looked hard in, then got up, walked over the hemento a hurried voice.  \"What'\n",
      " b'spelled, giving Harry Potter is buszed and silvery unperturned ropes of pance that Monday was not a fleas'], shape=(5,), dtype=string) \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 1.2780439853668213\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['Forest', 'the train', 'Platform', 'Bank', 'spell'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(100):\n",
    "    next_char, states = next_step_model.generate_next_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "\n",
    "print(result, '\\n\\n' + '_'*80)\n",
    "\n",
    "\n",
    "print(f\"\\nRun time: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "liked-scoop",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T00:15:42.956448Z",
     "start_time": "2021-02-07T00:15:37.893301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.NextStep object at 0x7f6f5405a2b0>, because it is not built.\n",
      "Input shape (5, None)\n",
      "Input shape (5, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: potterv2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: potterv2/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(next_step_model, 'potterv2')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
